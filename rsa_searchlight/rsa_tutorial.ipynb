{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5bfe10c",
   "metadata": {},
   "source": [
    "# Searchlight Analysis \n",
    "## with Representational Similarity Analysis method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d6633",
   "metadata": {},
   "source": [
    "Created for RSA Tutorial, LMG-MPIB, 12th April 2022,\n",
    "<p>Author: Izabela Maria Sztuka(imsztuka@protonmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455c389",
   "metadata": {},
   "source": [
    "## General notes:\n",
    "<p> The following script was created as an example of analysis pipeline for Searchlight (SA) using RSA method with RSA toolbox python version (it is python equivalent of the MATLAB toolbox). The SA is a multivariate technique that identifies a locally informative areas using small spherical subsets called 'searchlights' centred on every voxel. The mapped value for each voxel is derivative of the searchlight not individual voxel. It is primarily used for whole-brain analyses, however it is possible (and less computationally expernsive) to perform it on ROI only. Here, we will use the SA to identify the regions informative for the selected ARCH candidate models. We first, obtain searchlight accuracy map for each participant and then perform group-level analysis using one-sample t-test to obtain z-map of accuracies in searchlight. \n",
    "    \n",
    "<p> Searchlight analysis was performed using rsa method with py-rsatoolbox.\n",
    "https://rsatoolbox.readthedocs.io/en/latest/\n",
    "\n",
    "<p> for details on SA see: Etzel, J. A., Zacks, J. M., & Braver, T. S. (2013). Searchlight analysis: promise, pitfalls, and potential. NeuroImage, 78, 261â€“269. https://doi.org/10.1016/j.neuroimage.2013.03.041    \n",
    "    \n",
    "    \n",
    "#### packages needed to run it: \n",
    "\n",
    "- nilearn 0.8.1\n",
    "- nibabel 3.2.1\n",
    "- numpy  1.21.4\n",
    "- matplotlib 3.5.0\n",
    "- scipy 1.7.3\n",
    "- pandas 1.3.4\n",
    "- seaborn 0.11.2\n",
    "- tabulate (to print the cluster table)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfe201",
   "metadata": {},
   "source": [
    "## Workflow:\n",
    "\n",
    "1. Logistics. Loading necessary packages.\n",
    "2. Helper functions.\n",
    "3. Directories. CUSTOMISE HERE. \n",
    "\n",
    "<p> Group level analysis is performing one-sample ttest (with smoothing=3) with FDR correction. \n",
    "<p> The script is producing the z score files in .npy and .nii format.\n",
    "<p> Opt. visualise the map interactively or in static.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c88b7",
   "metadata": {},
   "source": [
    "**Logistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# ARCH-RSA searchlight second-level post rsa-method wholebrain searchlight.\n",
    "from nilearn import datasets\n",
    "import pandas as pd\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import image\n",
    "from nilearn import plotting\n",
    "from nilearn import masking\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import get_data, math_img\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "from nilearn.image import new_img_like\n",
    "from rsatoolbox.inference import eval_fixed\n",
    "from rsatoolbox.model import ModelFixed\n",
    "from rsatoolbox.rdm import RDMs\n",
    "from scipy import io\n",
    "from rsatoolbox.util.searchlight import get_volume_searchlight, get_searchlight_RDMs, evaluate_models_searchlight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80a594",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organise the RDM into upper triangular index and configure the matrices.\n",
    "def upper_tri(RDM):\n",
    "    \"\"\"upper_tri returns the upper triangular index of an RDM\n",
    "\n",
    "    Args:\n",
    "        RDM 2Darray: squareform RDM\n",
    "\n",
    "    Returns:\n",
    "        1D array: upper triangular vector of the RDM\n",
    "    \"\"\"\n",
    "    # returns the upper triangle\n",
    "    m = RDM.shape[0]\n",
    "    r, c = np.triu_indices(m, 1)\n",
    "    return RDM[r, c]\n",
    "\n",
    "import matplotlib.colors\n",
    "def RDMcolormapObject(direction=1):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib color map object for RSA and brain plotting\n",
    "    \"\"\"\n",
    "    if direction == 0:\n",
    "        cs = ['yellow', 'red', 'gray', 'turquoise', 'blue']\n",
    "    elif direction == 1:\n",
    "        cs = ['blue', 'turquoise', 'gray', 'red', 'yellow']\n",
    "    else:\n",
    "        raise ValueError('Direction needs to be 0 or 1')\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", cs)\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d84cd5",
   "metadata": {},
   "source": [
    "**Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185af552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "# DIRECTORY TO BETAS\n",
    "IN = '/home/mpib/sztuka/projects/RSA/derivatives/1Level/RSA_1stLevel_1stDeriv/'\n",
    "# DIRECTORY TO RESULTS\n",
    "OUT_brains = '/home/mpib/sztuka/projects/RSA/derivatives/py-searchlight/NA/Figures/'\n",
    "OUT_plots = '/home/mpib/sztuka/projects/RSA/derivatives/py-searchlight/NA/Plots/'\n",
    "OUT_scores = '/home/mpib/sztuka/projects/RSA/derivatives/py-searchlight/NA/Scores/'\n",
    "OUT_results = '/home/mpib/sztuka/projects/RSA/derivatives/py-searchlight/NA/Results/'\n",
    "#where you save the resulting group-level z-score\n",
    "grouplevel_z = '/Users/sztuka/Desktop/Searchlight/Tardis_deriv/Group_Level/z_score/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a133624",
   "metadata": {},
   "source": [
    "**Speficy subject IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f72eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_dir = ['sub-01','sub-02','sub-03','sub-04','sub-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c5b8d",
   "metadata": {},
   "source": [
    "**Subject-level Searchlight Analysis (loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(subs_dir)):\n",
    "# set this path to wherever you saved the folder containing the img-files\n",
    "    data_folder =  os.path.join(IN, subs_dir[i])\n",
    "    image_paths = list(glob(f\"{data_folder}/beta_*.nii\"))\n",
    "    image_paths.sort()\n",
    "    print(subs_dir[i]+' - images loaded')\n",
    "# load one image to get the dimensions and make the mask\n",
    "    tmp_img = nib.load(image_paths[0])\n",
    "    affine_mat = tmp_img.affine\n",
    "    dimsize = tmp_img.header.get_zooms()\n",
    "# we infer the mask by looking at non-nan voxels\n",
    "    mask = ~np.isnan(tmp_img.get_fdata())\n",
    "    x, y, z = tmp_img.get_fdata().shape\n",
    "# loop over all images\n",
    "    data = np.zeros((len(image_paths), x, y, z))\n",
    "    for x, im in enumerate(image_paths):\n",
    "        data[x] = nib.load(im).get_fdata()\n",
    "# only one pattern per image\n",
    "    image_value = np.arange(len(image_paths))\n",
    "# SPECIFY SEARCHLIGHT PARAMETERS\n",
    "    print(subs_dir[i]+' - looking for searchlights')\n",
    "    centers, neighbors = get_volume_searchlight(mask, radius=5, threshold=0.5)\n",
    "# reshape data so we have n_observastions x n_voxels\n",
    "    data_2d = data.reshape([data.shape[0], -1])\n",
    "    data_2d = np.nan_to_num(data_2d)\n",
    "# Get RDMs\n",
    "    print(subs_dir[i]+' - creating brain RDMs')\n",
    "    SL_RDM = get_searchlight_RDMs(data_2d, centers, neighbors, image_value, method='correlation')\n",
    "# load sub specific file from matlab MDS file:\n",
    "    print(subs_dir[i]+' - loading subjects dissimilarity matrix')\n",
    "#load Model from general file (CUSTOMISE THE DIRECTORY):\n",
    "    matlab_data = io.matlab.loadmat('/home/mpib/sztuka/projects/RSA/code/py-searchlight/NA/model_AN.mat')\n",
    "    matlab_data = matlab_data['AN']\n",
    "# This is difficult part:\n",
    "    an_labels = np.array(['I-C-A-1.jpg','I-C-A-10.jpg','I-C-A-11.jpg','I-C-A-3.jpg','I-C-A-4.jpg','I-E-A-1.jpg','I-E-A-2.jpg','I-E-A-3.jpg','I-E-A-5.jpg','I-E-A-7.jpg','I-G-A-1.jpg','I-G-A-14.jpg','I-G-A-20.jpg','I-G-A-3.jpg','I-G-A-8.jpg','I-H-A-22.jpg','I-H-A-29.jpg','I-H-A-5.jpg','I-H-A-51.jpg','I-H-A-7.jpg','I-M-A-10.jpg','I-M-A-11.jpg','I-M-A-13.jpg','I-M-A-14.jpg','I-M-A-16.jpg','I-R-A-20.jpg','I-R-A-21.jpg','I-R-A-23.jpg','I-R-A-25.jpg','I-R-A-9.jpg','I-C-N-1.jpg','I-C-N-11.jpg','I-C-N-2.jpg','I-C-N-3.jpg','I-C-N-7.jpg','I-E-N-1.jpg','I-E-N-2.jpg','I-E-N-3.jpg','I-E-N-4.jpg','I-E-N-6.jpg','I-G-N-1.jpg','I-G-N-13.jpg','I-G-N-16.jpg','I-G-N-5.jpg','I-G-N-7.jpg','I-H-N-29.jpg','I-H-N-39.jpg','I-H-N-41.jpg','I-H-N-44.jpg','I-H-N-7.jpg','I-M-N-1.jpg','I-M-N-4.jpg','I-M-N-5.jpg','I-M-N-6.jpg','I-M-N-8.jpg','I-R-N-10.jpg','I-R-N-12.jpg','I-R-N-21.jpg','I-R-N-22.jpg','I-R-N-23.jpg'])\n",
    "    an_RDM = matlab_data\n",
    "    an_model = ModelFixed('AN', upper_tri(an_RDM))\n",
    "# get the evaulation score for each voxel\n",
    "    eval_results = evaluate_models_searchlight(SL_RDM, an_model, eval_fixed, method='spearman', n_jobs=3)\n",
    "# We only have one model, but evaluations returns a list. By using float we just grab the value within that list\n",
    "    print(subs_dir[i]+' - running model comparison')\n",
    "    eval_score = [np.float(e.evaluations) for e in eval_results]\n",
    "    print(subs_dir[i]+' - scores saved and now in use for saving in version compatible with other applications')\n",
    "    file_n = 'ARCH_AN_score_'+ subs_dir[i]\n",
    "    file_nFigures = os.path.join(OUT_scores, file_n)\n",
    "    print(subs_dir[i]+' - saving scores')\n",
    "    np.save(file_nFigures,eval_score)\n",
    "# Create an 3D array, with the size of mask, and\n",
    "    x, y, z = mask.shape\n",
    "    RDM_brain = np.zeros([x*y*z])\n",
    "    RDM_brain[list(SL_RDM.rdm_descriptors['voxel_index'])] = eval_score\n",
    "    RDM_brain = RDM_brain.reshape([x, y, z])\n",
    "    print('End SearchLight for participant ' + subs_dir[i])\n",
    "# results for replication: (here you are saving RDM brain not only evaluation score)\n",
    "    file_nb = 'ARCH_AN_RDMbrain_'+ subs_dir[i]+'.npy'\n",
    "    file_nbFigures = os.path.join(OUT_scores, file_nb)\n",
    "    print(subs_dir[i]+' - saving scores')\n",
    "    np.save(file_nbFigures,RDM_brain)\n",
    "    output_name = 'ARCH_SL_AN_result_'+ subs_dir[i]+'.nii.gz'\n",
    "    output_dir = os.path.join(OUT_results,output_name)\n",
    "    sl_result = RDM_brain.astype('double')  # Convert the output into a precision format that can be used by other applications\n",
    "    sl_result[np.isnan(sl_result)] = 0  # Exchange nans with zero to ensure compatibility with other applications\n",
    "    sl_nii = nib.Nifti1Image(sl_result, affine_mat)  # create the volume image\n",
    "    hdr = sl_nii.header  # get a handle of the .nii file's header\n",
    "    nib.save(sl_nii, output_dir)  # Save the volume\n",
    "#plot results\n",
    "    sns.distplot(eval_score)\n",
    "    print(subs_dir[i]+' - saving distribution of correlations')\n",
    "    plt.title('Distributions of correlations', size=18)\n",
    "    plt.ylabel('Occurance', size=18)\n",
    "    plt.xlabel('Spearmann correlation', size=18)\n",
    "    sns.despine()\n",
    "    #plt.show()\n",
    "# sale the plot\n",
    "    figure_name = 'ARCH_SL_AN_DOC_'+ subs_dir[i]\n",
    "    filenameFigures = os.path.join(OUT_plots,figure_name)\n",
    "    plt.savefig(filenameFigures,dpi=800)\n",
    "# lets plot the voxels above the 99th percentile\n",
    "    threshold = np.percentile(eval_score, 99)\n",
    "    plot_img = new_img_like(tmp_img, RDM_brain)\n",
    "    cmap = RDMcolormapObject()\n",
    "    coords = range(-20, 40, 5)\n",
    "    print(subs_dir[i]+' - saving plot of voxels above 99th percentile')\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    display = plotting.plot_stat_map(\n",
    "        plot_img, colorbar=True, cut_coords=coords,threshold=threshold,\n",
    "        display_mode='z', draw_cross=False, figure=fig,\n",
    "        title=f'Model AN Evaluation'+ subs_dir[i], cmap=cmap,\n",
    "        black_bg=False, annotate=False)\n",
    "    #plt.show()\n",
    "    figure_name = 'ARCH_SL_AN_'+ subs_dir[i]\n",
    "    filenameFigures = os.path.join(OUT_brains, figure_name)\n",
    "    plt.savefig(filenameFigures,dpi=800)\n",
    "    print(subs_dir[i]+' - finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe29b2",
   "metadata": {},
   "source": [
    "**Inspecting the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9feadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aecc5ba",
   "metadata": {},
   "source": [
    "**Group-level inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER\n",
    "#name of the model in dir and file name\n",
    "# if model is in collective folder like Ratings, LLF or MDS then typy = 1 else it's 0\n",
    "typy = 0\n",
    "typt = 'LLF'\n",
    "# model name\n",
    "model_name = 'AlexNet'\n",
    "# if filename is different\n",
    "another_name = model_name\n",
    "\n",
    "# should be 34 all through.\n",
    "n_samples = 34\n",
    "\n",
    "# For dCNN ONLY: layer number\n",
    "layer = '10'\n",
    "# if using dCNN models =1 else keep 0\n",
    "dCNN = 1\n",
    "if dCNN == 1:\n",
    "    print(model_name+layer)\n",
    "else:\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bf93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set properties\n",
    "n_subjects=n_samples\n",
    "if typy == 1:\n",
    "    src = '/Users/sztuka/Desktop/Searchlight/Tardis_deriv/py-searchlight/py-searchlight/'+typt+'/'+model_name+'/Results/ARCH_SL_'+another_name+'_result_sub-*.nii.gz'\n",
    "else:\n",
    "    src = '/Users/sztuka/Desktop/Searchlight/Tardis_deriv/py-searchlight/py-searchlight/'+model_name+'/Results/ARCH_SL_'+another_name+'_result_sub-*.nii.gz'\n",
    "# Load the accuracy maps from searchlight. \n",
    "data_folder =  src\n",
    "cmap_filenames = list(glob(f\"{data_folder}\"))\n",
    "cmap_filenames.sort()\n",
    "tmp_img = nib.load(cmap_filenames[0])\n",
    "affine_mat = tmp_img.affine\n",
    "dimsize = tmp_img.header.get_zooms()\n",
    "# Construct design matrix & model\n",
    "design_matrix = pd.DataFrame([1] * n_samples, columns=['intercept'])\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm=3.0).fit(cmap_filenames, design_matrix=design_matrix)\n",
    "#Estimate model\n",
    "# output_type must be one of ['z_score', 'stat', 'p_value', 'effect_size', 'effect_variance', 'all']\n",
    "z_map = second_level_model.compute_contrast(second_level_stat_type='t',output_type='z_score')\n",
    "# save z_maps \n",
    "file_nb = 'ARCH_'+model_name+'_z_score.npy'\n",
    "file_csv = 'ARCH_'+model_name+'_z_score.nii'\n",
    "file_nbFigures = os.path.join(grouplevel_z, file_nb)\n",
    "np.save(file_nbFigures,z_map)\n",
    "sl_result = z_map \n",
    "sl_nii = nib.Nifti1Image(sl_result, affine_mat)  # create the volume image\n",
    "hdr = sl_nii.header  # get a handle of the .nii file's header\n",
    "output_dir = os.path.join(grouplevel_z, file_csv)\n",
    "nib.save(sl_result, output_dir)  # Save the volume\n",
    "print(model_name+' done deal!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913ab69",
   "metadata": {},
   "source": [
    "**Plot uncorrected values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the second level contrast at uncorrected p < 0.05 and plot it.\n",
    "p_val = 0.05\n",
    "p001_unc = norm.isf(p_val)\n",
    "display = plotting.plot_stat_map(\n",
    "    z_map, threshold=p001_unc, colorbar=True, display_mode='z',\n",
    "    title='SL'+model_name+'group level (uncorrected p<.05)')\n",
    "# plot the results:\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85565619",
   "metadata": {},
   "source": [
    "**Perform FDR correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df012d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fdr-corrected p = 0.05 threshold for these data\n",
    "_, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fdr')\n",
    "# Plot the second level contrast at the computed thresholds\n",
    "plotting.plot_stat_map(\n",
    "    z_map, threshold=threshold, colorbar=True,\n",
    "    title='Group-level '+model_name+' (fdr=0.05)')\n",
    "# plot the results: \n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd8dc5",
   "metadata": {},
   "source": [
    "**View interactively**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa575624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the view\n",
    "view = plotting.view_img(z_map, threshold=threshold, colorbar=True,\n",
    "    title='Group-level '+model_name+layer+' (fdr=0.05)')\n",
    "# view in the cell below\n",
    "#view\n",
    "# view in the browser\n",
    "view.open_in_browser()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
